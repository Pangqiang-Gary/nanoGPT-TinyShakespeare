{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7278,
     "status": "ok",
     "timestamp": 1762722852571,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "kOmQRjvQIuLk",
    "outputId": "8d9f6ff2-eacb-4f3b-dcd3-46027b025f6c"
   },
   "outputs": [],
   "source": [
    "!pip install torch tqdm numpy datasets transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1762722853124,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "a_DC8bI3eJ8d",
    "outputId": "87ddc75f-22a3-4427-8249-ba9e3d7310cf"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "text = requests.get(url).text\n",
    "print(\"data length：\", len(text))\n",
    "print(text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP7WG9Rqea9M"
   },
   "outputs": [],
   "source": [
    "n = len(text)\n",
    "train_text = text[:int(n*0.9)]\n",
    "val_text = text[int(n*0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9826,
     "status": "ok",
     "timestamp": 1762722862962,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "xIK2wqI4eqIH",
    "outputId": "346d8b31-e37e-405c-f4d3-b8a946a2de69"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "def encode(s): return [stoi[c] for c in s]  # str -> list[int]\n",
    "def decode(l): return ''.join([itos[i] for i in l])  # list[int] -> str\n",
    "\n",
    "train_data = torch.tensor(encode(train_text), dtype=torch.long)\n",
    "val_data = torch.tensor(encode(val_text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkzddJHSf5m2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class TinyGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=128, n_head=4, n_layer=4, block_size=128):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            nn.TransformerEncoderLayer(d_model=n_embd, nhead=n_head)\n",
    "            for _ in range(n_layer)\n",
    "        ])\n",
    "        self.ln = nn.LayerNorm(n_embd)\n",
    "        self.fc = nn.Linear(n_embd, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195358,
     "status": "ok",
     "timestamp": 1762723058341,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "3Gzz1wTChUIn",
    "outputId": "41c4929a-10b4-472d-d8f6-53daf3a16938"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import trange\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = TinyGPT(vocab_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    losses = {'train':0, 'val':0}\n",
    "    with torch.no_grad():\n",
    "        for split in ['train', 'val']:\n",
    "            loss_sum = 0\n",
    "            for _ in range(10):\n",
    "                x, y = get_batch(split)\n",
    "                logits = model(x)\n",
    "                loss = F.cross_entropy(logits.view(-1, vocab_size), y.view(-1))\n",
    "                loss_sum += loss.item()\n",
    "            losses[split] = loss_sum / 10\n",
    "    model.train()\n",
    "    return losses\n",
    "\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "for epoch in trange(epochs):\n",
    "    x, y = get_batch('train')\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits.view(-1, vocab_size), y.view(-1))\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(losses)\n",
    "\n",
    "train_time = (time.time() - start_time) / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26860,
     "status": "ok",
     "timestamp": 1762723085212,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "7tshe2EEiRvh",
    "outputId": "ac0738bf-6cb6-48e2-c8c6-c0194c8786e9"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "losses = estimate_loss()\n",
    "val_ppl = math.exp(losses['val'])\n",
    "train_ppl = math.exp(losses['train'])\n",
    "val_minus_train = val_ppl - train_ppl\n",
    "\n",
    "tokens_per_sec = (len(train_data) * epochs) / (train_time * 60)\n",
    "total_tokens = len(train_data) * epochs\n",
    "\n",
    "metrics = {\n",
    "    \"val_perplexity\": val_ppl,\n",
    "    \"num_parameters\": num_params,\n",
    "    \"tokens_per_sec\": tokens_per_sec,\n",
    "    \"training_time_minutes\": train_time,\n",
    "    \"val_minus_train\": val_minus_train,\n",
    "    \"total_tokens_processed\": total_tokens\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame([metrics]).to_csv(\"submission.csv\", index=False)\n",
    "print(pd.DataFrame([metrics]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9eDYg4TZlmO"
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"Pangqiang-Gary\"\n",
    "!git config --global user.email \"pangqiang02@gmail.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1762723085730,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "iCYOSyhNZ0ZO",
    "outputId": "e23b2d33-b3a0-4fe6-820d-0b7fefa0f140"
   },
   "outputs": [],
   "source": [
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Initial commit - upload TinyGPT project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1762723085847,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "kiit2wataDrb",
    "outputId": "58640b36-92db-489e-a29c-3dcbcd798f7f"
   },
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/Pangqiang-Gary/nanoGPT-TinyShakespeare.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fzjo5MYaKRI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GITHUB_TOKEN'] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11878,
     "status": "ok",
     "timestamp": 1762723097733,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "yuSvz3s8dI0K",
    "outputId": "37522322-8ce1-4384-dec4-470409e497f0"
   },
   "outputs": [],
   "source": [
    "!git remote set-url origin https://Pangqiang-Gary:${GITHUB_TOKEN}@github.com/Pangqiang-Gary/nanoGPT-TinyShakespeare.git\n",
    "!git push -u origin main --force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1762723097846,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "bsr8EhZLd9px",
    "outputId": "c0384b56-7ead-48ec-ee39-11c063f3f8a9"
   },
   "outputs": [],
   "source": [
    "# 1️⃣ 确认你当前目录下有哪些文件\n",
    "!ls -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29684,
     "status": "ok",
     "timestamp": 1762723636078,
     "user": {
      "displayName": "DEQIANG YE",
      "userId": "10726330070638215286"
     },
     "user_tz": 300
    },
    "id": "5bIwO-Boday-",
    "outputId": "487f7b70-0189-47dc-b87f-ebce5fee7cad"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWeJxwIEhIdN",
    "outputId": "f96e47b4-5ac2-47e6-a3aa-04ad7e63a77e"
   },
   "outputs": [],
   "source": [
    "# 查看你的 Colab Notebooks 目录，确认文件名\n",
    "!ls \"/content/drive/My Drive/Colab Notebooks\"\n",
    "\n",
    "# 把笔记本复制到 /content 并用不含空格的名字\n",
    "!cp \"/content/drive/My Drive/Colab Notebooks/nanoGPT_TinyShakespeare.ipynb\" \"/content/nanoGPT_TinyShakespeare.ipynb\"\n",
    "\n",
    "# 确认现在 /content 里有这个文件\n",
    "!ls -a\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZsSEU8ATsT5PYI5zfCyhL",
   "provenance": [
    {
     "file_id": "120nV6x7Hy7xQzpCZ13lAZz4a-Vq8lVdU",
     "timestamp": 1762723549507
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
